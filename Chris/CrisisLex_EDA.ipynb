{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, time, re, nltk, hdbscan, spacy, string\n",
    "import psycopg2 as pg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sys import getsizeof\n",
    "from datetime import datetime\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from psycopg2.extras import RealDictCursor, Json\n",
    "from spacy.lang.en.examples import sentences\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_format_log(file_path, \n",
    "                        logfile = 'assets/file_log.txt', \n",
    "                        now = round(time.time()), \n",
    "                        file_description = None): \n",
    "   \n",
    "    try:\n",
    "        ext = re.search('(?<!^)(?<!\\.)\\.(?!\\.)', file_path).start() \n",
    "    except:\n",
    "        raise NameError('Please enter a relative path with a file extension.') \n",
    "    \n",
    "    stamp = re.search('(?<!^)(?<!\\.)[a-z]+_[a-z]+(?=\\.)', file_path).start()\n",
    "    formatted_name = f'{file_path[:stamp]}{now}_{file_path[stamp:]}'  \n",
    "    if not file_description:\n",
    "        file_description = f'Word list saved at: {time.asctime(time.gmtime(now))}'\n",
    "    with open(logfile, 'a+') as f:\n",
    "        f.write(f'{formatted_name}: {file_description}\\n')\n",
    "    return formatted_name, now, file_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandy_df = pd.read_csv('data/CrisisLexT6/2012_Sandy_Hurricane/2012_Sandy_Hurricane-ontopic_offtopic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'262596552399396864'</td>\n",
       "      <td>I've got enough candles to supply a Mexican fa...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'263044104500420609'</td>\n",
       "      <td>Sandy be soooo mad that she be shattering our ...</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'263309629973491712'</td>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'263422851133079552'</td>\n",
       "      <td>@taos you never got that magnificent case of B...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'262404311223504896'</td>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, N...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '262596552399396864'  I've got enough candles to supply a Mexican fa...   \n",
       "1  '263044104500420609'  Sandy be soooo mad that she be shattering our ...   \n",
       "2  '263309629973491712'  @ibexgirl thankfully Hurricane Waugh played it...   \n",
       "3  '263422851133079552'  @taos you never got that magnificent case of B...   \n",
       "4  '262404311223504896'  I'm at Mad River Bar &amp; Grille (New York, N...   \n",
       "\n",
       "       label  \n",
       "0  off-topic  \n",
       "1   on-topic  \n",
       "2  off-topic  \n",
       "3  off-topic  \n",
       "4  off-topic  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandy_df['type'] = 'hurricane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'262596552399396864'</td>\n",
       "      <td>I've got enough candles to supply a Mexican fa...</td>\n",
       "      <td>off-topic</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'263044104500420609'</td>\n",
       "      <td>Sandy be soooo mad that she be shattering our ...</td>\n",
       "      <td>on-topic</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'263309629973491712'</td>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it...</td>\n",
       "      <td>off-topic</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'263422851133079552'</td>\n",
       "      <td>@taos you never got that magnificent case of B...</td>\n",
       "      <td>off-topic</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'262404311223504896'</td>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, N...</td>\n",
       "      <td>off-topic</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '262596552399396864'  I've got enough candles to supply a Mexican fa...   \n",
       "1  '263044104500420609'  Sandy be soooo mad that she be shattering our ...   \n",
       "2  '263309629973491712'  @ibexgirl thankfully Hurricane Waugh played it...   \n",
       "3  '263422851133079552'  @taos you never got that magnificent case of B...   \n",
       "4  '262404311223504896'  I'm at Mad River Bar &amp; Grille (New York, N...   \n",
       "\n",
       "       label       type  \n",
       "0  off-topic  hurricane  \n",
       "1   on-topic  hurricane  \n",
       "2  off-topic  hurricane  \n",
       "3  off-topic  hurricane  \n",
       "4  off-topic  hurricane  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet id', ' tweet', ' label', 'type'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandy_df.rename(columns={' tweet':'tweet'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandy_df.rename(columns={' label':'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandy_df['label'] = sandy_df['label'].map(lambda x: 1 if x=='on-topic' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'262596552399396864'</td>\n",
       "      <td>I've got enough candles to supply a Mexican fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'263044104500420609'</td>\n",
       "      <td>Sandy be soooo mad that she be shattering our ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'263309629973491712'</td>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'263422851133079552'</td>\n",
       "      <td>@taos you never got that magnificent case of B...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'262404311223504896'</td>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, N...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '262596552399396864'  I've got enough candles to supply a Mexican fa...   \n",
       "1  '263044104500420609'  Sandy be soooo mad that she be shattering our ...   \n",
       "2  '263309629973491712'  @ibexgirl thankfully Hurricane Waugh played it...   \n",
       "3  '263422851133079552'  @taos you never got that magnificent case of B...   \n",
       "4  '262404311223504896'  I'm at Mad River Bar &amp; Grille (New York, N...   \n",
       "\n",
       "   label       type  \n",
       "0      0  hurricane  \n",
       "1      1  hurricane  \n",
       "2      0  hurricane  \n",
       "3      0  hurricane  \n",
       "4      0  hurricane  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10008, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_df = pd.read_csv('data/CrisisLexT6/2013_Alberta_Floods/2013_Alberta_Floods-ontopic_offtopic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'348351442404376578'</td>\n",
       "      <td>@Jay1972Jay Nope. Mid 80's. It's off Metallica...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'348167215536803841'</td>\n",
       "      <td>Nothing like a :16 second downpour to give us ...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'348644655786778624'</td>\n",
       "      <td>@NelsonTagoona so glad that you missed the flo...</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'350519668815036416'</td>\n",
       "      <td>Party hard , suns down , still warm , lovin li...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'351446519733432320'</td>\n",
       "      <td>@Exclusionzone if you compare yourself to wate...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '348351442404376578'  @Jay1972Jay Nope. Mid 80's. It's off Metallica...   \n",
       "1  '348167215536803841'  Nothing like a :16 second downpour to give us ...   \n",
       "2  '348644655786778624'  @NelsonTagoona so glad that you missed the flo...   \n",
       "3  '350519668815036416'  Party hard , suns down , still warm , lovin li...   \n",
       "4  '351446519733432320'  @Exclusionzone if you compare yourself to wate...   \n",
       "\n",
       "       label  \n",
       "0  off-topic  \n",
       "1  off-topic  \n",
       "2   on-topic  \n",
       "3  off-topic  \n",
       "4  off-topic  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alberta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_df['type'] = 'flood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet id', ' tweet', ' label', 'type'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alberta_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_df.rename(columns={' tweet':'tweet'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_df.rename(columns={' label':'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alberta_df['label'] = alberta_df['label'].map(lambda x: 1 if x=='on-topic' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'348351442404376578'</td>\n",
       "      <td>@Jay1972Jay Nope. Mid 80's. It's off Metallica...</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'348167215536803841'</td>\n",
       "      <td>Nothing like a :16 second downpour to give us ...</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'348644655786778624'</td>\n",
       "      <td>@NelsonTagoona so glad that you missed the flo...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'350519668815036416'</td>\n",
       "      <td>Party hard , suns down , still warm , lovin li...</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'351446519733432320'</td>\n",
       "      <td>@Exclusionzone if you compare yourself to wate...</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '348351442404376578'  @Jay1972Jay Nope. Mid 80's. It's off Metallica...   \n",
       "1  '348167215536803841'  Nothing like a :16 second downpour to give us ...   \n",
       "2  '348644655786778624'  @NelsonTagoona so glad that you missed the flo...   \n",
       "3  '350519668815036416'  Party hard , suns down , still warm , lovin li...   \n",
       "4  '351446519733432320'  @Exclusionzone if you compare yourself to wate...   \n",
       "\n",
       "   label   type  \n",
       "0      0  flood  \n",
       "1      0  flood  \n",
       "2      1  flood  \n",
       "3      0  flood  \n",
       "4      0  flood  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alberta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10031, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alberta_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oklahoma_df = pd.read_csv('data/CrisisLexT6/2013_Oklahoma_Tornado/2013_Oklahoma_Tornado-ontopic_offtopic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'336908711324962817'</td>\n",
       "      <td>@HeatleyJheat44 its barley even raining where ...</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'337052158035890176'</td>\n",
       "      <td>Sorry I can't do anything right.</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'339338021751103488'</td>\n",
       "      <td>@mrwendell29: @BradSowderWX  says we have the ...</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'336339509077762051'</td>\n",
       "      <td>#honestyhour I like to wear half split running...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'337734129972035584'</td>\n",
       "      <td>I'm too stressed to have a good summer</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '336908711324962817'  @HeatleyJheat44 its barley even raining where ...   \n",
       "1  '337052158035890176'                   Sorry I can't do anything right.   \n",
       "2  '339338021751103488'  @mrwendell29: @BradSowderWX  says we have the ...   \n",
       "3  '336339509077762051'  #honestyhour I like to wear half split running...   \n",
       "4  '337734129972035584'             I'm too stressed to have a good summer   \n",
       "\n",
       "       label  \n",
       "0   on-topic  \n",
       "1  off-topic  \n",
       "2   on-topic  \n",
       "3  off-topic  \n",
       "4  off-topic  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oklahoma_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oklahoma_df['type'] = 'tornado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet id', ' tweet', ' label', 'type'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oklahoma_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oklahoma_df.rename(columns={' tweet':'tweet'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oklahoma_df.rename(columns={' label':'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oklahoma_df['label'] = oklahoma_df['label'].map(lambda x: 1 if x=='on-topic' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'336908711324962817'</td>\n",
       "      <td>@HeatleyJheat44 its barley even raining where ...</td>\n",
       "      <td>1</td>\n",
       "      <td>tornado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'337052158035890176'</td>\n",
       "      <td>Sorry I can't do anything right.</td>\n",
       "      <td>0</td>\n",
       "      <td>tornado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'339338021751103488'</td>\n",
       "      <td>@mrwendell29: @BradSowderWX  says we have the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>tornado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'336339509077762051'</td>\n",
       "      <td>#honestyhour I like to wear half split running...</td>\n",
       "      <td>0</td>\n",
       "      <td>tornado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'337734129972035584'</td>\n",
       "      <td>I'm too stressed to have a good summer</td>\n",
       "      <td>0</td>\n",
       "      <td>tornado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '336908711324962817'  @HeatleyJheat44 its barley even raining where ...   \n",
       "1  '337052158035890176'                   Sorry I can't do anything right.   \n",
       "2  '339338021751103488'  @mrwendell29: @BradSowderWX  says we have the ...   \n",
       "3  '336339509077762051'  #honestyhour I like to wear half split running...   \n",
       "4  '337734129972035584'             I'm too stressed to have a good summer   \n",
       "\n",
       "   label     type  \n",
       "0      1  tornado  \n",
       "1      0  tornado  \n",
       "2      1  tornado  \n",
       "3      0  tornado  \n",
       "4      0  tornado  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oklahoma_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9992, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oklahoma_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queensland_df = pd.read_csv('data/CrisisLexT6/2013_Queensland_Floods/2013_Queensland_Floods-ontopic_offtopic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'296728042179534848'</td>\n",
       "      <td>@MarkSDobson I always thought that, big lad ai...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'296085045645570048'</td>\n",
       "      <td>@thamonstar a lot of water moving around and a...</td>\n",
       "      <td>on-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'296811076400603136'</td>\n",
       "      <td>Craig Thompson to be extradited to Victoria on...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'295357934387486720'</td>\n",
       "      <td>Sunshine state, sort your shit out.</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'296390762210398210'</td>\n",
       "      <td>@MarkPhilippi yeah I saw it. He's a wanker. Pa...</td>\n",
       "      <td>off-topic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '296728042179534848'  @MarkSDobson I always thought that, big lad ai...   \n",
       "1  '296085045645570048'  @thamonstar a lot of water moving around and a...   \n",
       "2  '296811076400603136'  Craig Thompson to be extradited to Victoria on...   \n",
       "3  '295357934387486720'                Sunshine state, sort your shit out.   \n",
       "4  '296390762210398210'  @MarkPhilippi yeah I saw it. He's a wanker. Pa...   \n",
       "\n",
       "       label  \n",
       "0  off-topic  \n",
       "1   on-topic  \n",
       "2  off-topic  \n",
       "3  off-topic  \n",
       "4  off-topic  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queensland_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queensland_df['type'] = 'flood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet id', ' tweet', ' label', 'type'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queensland_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queensland_df.rename(columns={' tweet':'tweet'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queensland_df.rename(columns={' label':'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queensland_df['label'] = queensland_df['label'].map(lambda x: 1 if x=='on-topic' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'296728042179534848'</td>\n",
       "      <td>@MarkSDobson I always thought that, big lad ai...</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'296085045645570048'</td>\n",
       "      <td>@thamonstar a lot of water moving around and a...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'296811076400603136'</td>\n",
       "      <td>Craig Thompson to be extradited to Victoria on...</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'295357934387486720'</td>\n",
       "      <td>Sunshine state, sort your shit out.</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'296390762210398210'</td>\n",
       "      <td>@MarkPhilippi yeah I saw it. He's a wanker. Pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '296728042179534848'  @MarkSDobson I always thought that, big lad ai...   \n",
       "1  '296085045645570048'  @thamonstar a lot of water moving around and a...   \n",
       "2  '296811076400603136'  Craig Thompson to be extradited to Victoria on...   \n",
       "3  '295357934387486720'                Sunshine state, sort your shit out.   \n",
       "4  '296390762210398210'  @MarkPhilippi yeah I saw it. He's a wanker. Pa...   \n",
       "\n",
       "   label   type  \n",
       "0      0  flood  \n",
       "1      1  flood  \n",
       "2      0  flood  \n",
       "3      0  flood  \n",
       "4      0  flood  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queensland_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10033, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queensland_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df = pd.concat([sandy_df, alberta_df, oklahoma_df, queensland_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'262596552399396864'</td>\n",
       "      <td>I've got enough candles to supply a Mexican fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'263044104500420609'</td>\n",
       "      <td>Sandy be soooo mad that she be shattering our ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'263309629973491712'</td>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'263422851133079552'</td>\n",
       "      <td>@taos you never got that magnificent case of B...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'262404311223504896'</td>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, N...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'263101347421888513'</td>\n",
       "      <td>Neighborly duties. @Cory_Kennedy arrives to th...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'262763437325684736'</td>\n",
       "      <td>And that's it until the spring.</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'263298821189156865'</td>\n",
       "      <td>I don't know how I'm getting back to Jersey si...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'262813023515865088'</td>\n",
       "      <td>@NaeemPeena We were asked to get off the plane...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'262998165282762752'</td>\n",
       "      <td>@jaytee_96 you must be crazy! &amp;amp; omg you tw...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'262914476989358080'</td>\n",
       "      <td>Already flooded so much #SANDY @ Hoboken http:...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>'262574187141541888'</td>\n",
       "      <td>@eloreeeeeee need me to comeback and finish it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'262991999911743490'</td>\n",
       "      <td>On that note, i pray that everyone stays safe,...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'262767536540643329'</td>\n",
       "      <td>@codyfinz my house is creeking... Does that me...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'262984888020504578'</td>\n",
       "      <td>My mom just found my little sister screaming o...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>'262970751861260288'</td>\n",
       "      <td>RT @FrankIero: Droplets of water is literally ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>'262690350051770368'</td>\n",
       "      <td>@NevaTRUST_Again I Dnt No If She Gonna Let Me</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'263059088869556224'</td>\n",
       "      <td>@jennettemccurdy @noahmunck He's got that kind...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'262653983838048256'</td>\n",
       "      <td>debating going home in prep for #sandy</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'262998057216516096'</td>\n",
       "      <td>@viamadison Thanks, babe. We all appreciate it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>'262768220375756800'</td>\n",
       "      <td>I can't taste my damn food .</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>'262771779553087488'</td>\n",
       "      <td>By 11am it's going to be 100% chance of rain #...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>'262344750932299777'</td>\n",
       "      <td>Big Daddy Deco ready for this Halloween party ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>'263090063473254400'</td>\n",
       "      <td>@MSLWILLSEE loll I don't know your twitter nam...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'262729320777256961'</td>\n",
       "      <td>@lisanewmn I do it all the time. Don't hate me...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'263047213490507776'</td>\n",
       "      <td>@newscaster we are 5 blocks from the water. Fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>'263041963757031425'</td>\n",
       "      <td>It's crazy out there, not gonna lie I'm kind o...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>'263160409115222016'</td>\n",
       "      <td>@israilov1012 god bless them ! Lmao the wind c...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'262624184029556736'</td>\n",
       "      <td>No sooner then my last tweet did I receive thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>'262764842253946880'</td>\n",
       "      <td>@mike_cucci queen duck face    ((((I can't do ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>'295783617198690304'</td>\n",
       "      <td>[GLOBAL NEWS] Flood worsens in eastern Austral...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>'295708638373376001'</td>\n",
       "      <td>Thoughts go out to all Australia,\\\\some in flo...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>'295618362317369344'</td>\n",
       "      <td>RT @CasReeves: #ChristianFollowTrain please pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>'295475609570779136'</td>\n",
       "      <td>RT @7NewsBrisbane: Foam from rough waves at Al...</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>'296484377309888512'</td>\n",
       "      <td>@OneNewsAlerts Why does Queensland insist on u...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>'295787478336561152'</td>\n",
       "      <td>RT @Sandra_Sully Tonight at 5 - Emergency serv...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>'296079518215598081'</td>\n",
       "      <td>RT @AJEnglish: Deadly flood waters rise in eas...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>'296444290836594689'</td>\n",
       "      <td>RT @an_news: Vast areas in two states underwat...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>'297100863296634880'</td>\n",
       "      <td>Newman has been misquoted about wanting to mak...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>'296123861781594112'</td>\n",
       "      <td>Military called in as deadly floods batter Aus...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>'295866233935519744'</td>\n",
       "      <td>Baby stuffed in bag, hoisted from flood: Austr...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>'295784292175446017'</td>\n",
       "      <td>@R1Breakfast @AllTimeLow id say 2.3 considerin...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>'296559719173193729'</td>\n",
       "      <td>I liked a @YouTube video from @HarvestArmy htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016</th>\n",
       "      <td>'295853473558298624'</td>\n",
       "      <td>RT @AnnastaciaMP: The Queensland Flood Appeal ...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>'296162858083942400'</td>\n",
       "      <td>Australia shows how #extremeweather brings vol...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10018</th>\n",
       "      <td>'295865870314512384'</td>\n",
       "      <td>Baby stuffed in bag, hoisted from flood: Austr...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>'296396261374980096'</td>\n",
       "      <td>AUSTRALIA: See latest on flood warnings with @...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>'295801647098126336'</td>\n",
       "      <td>#blueready news  City by city, town by town, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10021</th>\n",
       "      <td>'295866318702387200'</td>\n",
       "      <td>Baby stuffed in bag, hoisted from flood: Austr...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>'295758965919318016'</td>\n",
       "      <td>RT @abcnews: LIVE: Queensland Premier Campbell...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023</th>\n",
       "      <td>'295815270663090176'</td>\n",
       "      <td>Queensland flood victims pay $11.00 for a cup ...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10024</th>\n",
       "      <td>'296247096200282112'</td>\n",
       "      <td>RT @newscientist: Climate change blamed as #Au...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025</th>\n",
       "      <td>'295866103974993920'</td>\n",
       "      <td>Baby stuffed in bag, hoisted from flood: Austr...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>'295734452968116225'</td>\n",
       "      <td>RT @bravotrav: Tony Abbott is visiting flood a...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10027</th>\n",
       "      <td>'296390817063530497'</td>\n",
       "      <td>GOODNA: Australia flood danger far from over -...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10028</th>\n",
       "      <td>'295771687755063297'</td>\n",
       "      <td>RT @aus_politics: Abbott raises spectre of new...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10029</th>\n",
       "      <td>'295733360620363776'</td>\n",
       "      <td>RT @bravotrav: Tony Abbott is visiting flood a...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10030</th>\n",
       "      <td>'295464508074360832'</td>\n",
       "      <td>RT @9NewsGoldCoast: Much of Queensland is toni...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>'296225704784314368'</td>\n",
       "      <td>.@GeodesignB  #flood barrier now set up in #Au...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10032</th>\n",
       "      <td>'295764650597949441'</td>\n",
       "      <td>Telstra flies in crew to repair flood-damaged ...</td>\n",
       "      <td>1</td>\n",
       "      <td>flood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40064 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet id  \\\n",
       "0      '262596552399396864'   \n",
       "1      '263044104500420609'   \n",
       "2      '263309629973491712'   \n",
       "3      '263422851133079552'   \n",
       "4      '262404311223504896'   \n",
       "5      '263101347421888513'   \n",
       "6      '262763437325684736'   \n",
       "7      '263298821189156865'   \n",
       "8      '262813023515865088'   \n",
       "9      '262998165282762752'   \n",
       "10     '262914476989358080'   \n",
       "11     '262574187141541888'   \n",
       "12     '262991999911743490'   \n",
       "13     '262767536540643329'   \n",
       "14     '262984888020504578'   \n",
       "15     '262970751861260288'   \n",
       "16     '262690350051770368'   \n",
       "17     '263059088869556224'   \n",
       "18     '262653983838048256'   \n",
       "19     '262998057216516096'   \n",
       "20     '262768220375756800'   \n",
       "21     '262771779553087488'   \n",
       "22     '262344750932299777'   \n",
       "23     '263090063473254400'   \n",
       "24     '262729320777256961'   \n",
       "25     '263047213490507776'   \n",
       "26     '263041963757031425'   \n",
       "27     '263160409115222016'   \n",
       "28     '262624184029556736'   \n",
       "29     '262764842253946880'   \n",
       "...                     ...   \n",
       "10003  '295783617198690304'   \n",
       "10004  '295708638373376001'   \n",
       "10005  '295618362317369344'   \n",
       "10006  '295475609570779136'   \n",
       "10007  '296484377309888512'   \n",
       "10008  '295787478336561152'   \n",
       "10009  '296079518215598081'   \n",
       "10010  '296444290836594689'   \n",
       "10011  '297100863296634880'   \n",
       "10012  '296123861781594112'   \n",
       "10013  '295866233935519744'   \n",
       "10014  '295784292175446017'   \n",
       "10015  '296559719173193729'   \n",
       "10016  '295853473558298624'   \n",
       "10017  '296162858083942400'   \n",
       "10018  '295865870314512384'   \n",
       "10019  '296396261374980096'   \n",
       "10020  '295801647098126336'   \n",
       "10021  '295866318702387200'   \n",
       "10022  '295758965919318016'   \n",
       "10023  '295815270663090176'   \n",
       "10024  '296247096200282112'   \n",
       "10025  '295866103974993920'   \n",
       "10026  '295734452968116225'   \n",
       "10027  '296390817063530497'   \n",
       "10028  '295771687755063297'   \n",
       "10029  '295733360620363776'   \n",
       "10030  '295464508074360832'   \n",
       "10031  '296225704784314368'   \n",
       "10032  '295764650597949441'   \n",
       "\n",
       "                                                   tweet  label       type  \n",
       "0      I've got enough candles to supply a Mexican fa...      0  hurricane  \n",
       "1      Sandy be soooo mad that she be shattering our ...      1  hurricane  \n",
       "2      @ibexgirl thankfully Hurricane Waugh played it...      0  hurricane  \n",
       "3      @taos you never got that magnificent case of B...      0  hurricane  \n",
       "4      I'm at Mad River Bar &amp; Grille (New York, N...      0  hurricane  \n",
       "5      Neighborly duties. @Cory_Kennedy arrives to th...      1  hurricane  \n",
       "6                        And that's it until the spring.      0  hurricane  \n",
       "7      I don't know how I'm getting back to Jersey si...      1  hurricane  \n",
       "8      @NaeemPeena We were asked to get off the plane...      0  hurricane  \n",
       "9      @jaytee_96 you must be crazy! &amp; omg you tw...      0  hurricane  \n",
       "10     Already flooded so much #SANDY @ Hoboken http:...      1  hurricane  \n",
       "11     @eloreeeeeee need me to comeback and finish it...      0  hurricane  \n",
       "12     On that note, i pray that everyone stays safe,...      1  hurricane  \n",
       "13     @codyfinz my house is creeking... Does that me...      1  hurricane  \n",
       "14     My mom just found my little sister screaming o...      0  hurricane  \n",
       "15     RT @FrankIero: Droplets of water is literally ...      0  hurricane  \n",
       "16         @NevaTRUST_Again I Dnt No If She Gonna Let Me      0  hurricane  \n",
       "17     @jennettemccurdy @noahmunck He's got that kind...      0  hurricane  \n",
       "18                debating going home in prep for #sandy      1  hurricane  \n",
       "19     @viamadison Thanks, babe. We all appreciate it...      0  hurricane  \n",
       "20                          I can't taste my damn food .      0  hurricane  \n",
       "21     By 11am it's going to be 100% chance of rain #...      1  hurricane  \n",
       "22     Big Daddy Deco ready for this Halloween party ...      0  hurricane  \n",
       "23     @MSLWILLSEE loll I don't know your twitter nam...      0  hurricane  \n",
       "24     @lisanewmn I do it all the time. Don't hate me...      0  hurricane  \n",
       "25     @newscaster we are 5 blocks from the water. Fi...      1  hurricane  \n",
       "26     It's crazy out there, not gonna lie I'm kind o...      1  hurricane  \n",
       "27     @israilov1012 god bless them ! Lmao the wind c...      1  hurricane  \n",
       "28     No sooner then my last tweet did I receive thi...      0  hurricane  \n",
       "29     @mike_cucci queen duck face    ((((I can't do ...      0  hurricane  \n",
       "...                                                  ...    ...        ...  \n",
       "10003  [GLOBAL NEWS] Flood worsens in eastern Austral...      1      flood  \n",
       "10004  Thoughts go out to all Australia,\\\\some in flo...      1      flood  \n",
       "10005  RT @CasReeves: #ChristianFollowTrain please pr...      1      flood  \n",
       "10006  RT @7NewsBrisbane: Foam from rough waves at Al...      0      flood  \n",
       "10007  @OneNewsAlerts Why does Queensland insist on u...      1      flood  \n",
       "10008  RT @Sandra_Sully Tonight at 5 - Emergency serv...      1      flood  \n",
       "10009  RT @AJEnglish: Deadly flood waters rise in eas...      1      flood  \n",
       "10010  RT @an_news: Vast areas in two states underwat...      1      flood  \n",
       "10011  Newman has been misquoted about wanting to mak...      1      flood  \n",
       "10012  Military called in as deadly floods batter Aus...      1      flood  \n",
       "10013  Baby stuffed in bag, hoisted from flood: Austr...      1      flood  \n",
       "10014  @R1Breakfast @AllTimeLow id say 2.3 considerin...      1      flood  \n",
       "10015  I liked a @YouTube video from @HarvestArmy htt...      1      flood  \n",
       "10016  RT @AnnastaciaMP: The Queensland Flood Appeal ...      1      flood  \n",
       "10017  Australia shows how #extremeweather brings vol...      1      flood  \n",
       "10018  Baby stuffed in bag, hoisted from flood: Austr...      1      flood  \n",
       "10019  AUSTRALIA: See latest on flood warnings with @...      1      flood  \n",
       "10020  #blueready news  City by city, town by town, t...      1      flood  \n",
       "10021  Baby stuffed in bag, hoisted from flood: Austr...      1      flood  \n",
       "10022  RT @abcnews: LIVE: Queensland Premier Campbell...      1      flood  \n",
       "10023  Queensland flood victims pay $11.00 for a cup ...      1      flood  \n",
       "10024  RT @newscientist: Climate change blamed as #Au...      1      flood  \n",
       "10025  Baby stuffed in bag, hoisted from flood: Austr...      1      flood  \n",
       "10026  RT @bravotrav: Tony Abbott is visiting flood a...      1      flood  \n",
       "10027  GOODNA: Australia flood danger far from over -...      1      flood  \n",
       "10028  RT @aus_politics: Abbott raises spectre of new...      1      flood  \n",
       "10029  RT @bravotrav: Tony Abbott is visiting flood a...      1      flood  \n",
       "10030  RT @9NewsGoldCoast: Much of Queensland is toni...      1      flood  \n",
       "10031  .@GeodesignB  #flood barrier now set up in #Au...      1      flood  \n",
       "10032  Telstra flies in crew to repair flood-damaged ...      1      flood  \n",
       "\n",
       "[40064 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crisislex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = crisislex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'262596552399396864'</td>\n",
       "      <td>I've got enough candles to supply a Mexican fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'263044104500420609'</td>\n",
       "      <td>Sandy be soooo mad that she be shattering our ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'263309629973491712'</td>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'263422851133079552'</td>\n",
       "      <td>@taos you never got that magnificent case of B...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'262404311223504896'</td>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, N...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '262596552399396864'  I've got enough candles to supply a Mexican fa...   \n",
       "1  '263044104500420609'  Sandy be soooo mad that she be shattering our ...   \n",
       "2  '263309629973491712'  @ibexgirl thankfully Hurricane Waugh played it...   \n",
       "3  '263422851133079552'  @taos you never got that magnificent case of B...   \n",
       "4  '262404311223504896'  I'm at Mad River Bar &amp; Grille (New York, N...   \n",
       "\n",
       "   label       type  \n",
       "0      0  hurricane  \n",
       "1      1  hurricane  \n",
       "2      0  hurricane  \n",
       "3      0  hurricane  \n",
       "4      0  hurricane  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet id', 'tweet', 'label', 'type'], dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Eliminate hastags\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #Remove @ signs\n",
    "    tweet = re.sub('@', '', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = [i for i in df['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I've got enough candles to supply a Mexican family\",\n",
       " 'Sandy be soooo mad that she be shattering our doors and shiet #HurricaneSandy',\n",
       " '@ibexgirl thankfully Hurricane Waugh played it cool and waited this one out. Ready to go at any moment tho.',\n",
       " '@taos you never got that magnificent case of Burgundy I sent you to thank you for your tweets?',\n",
       " \"I'm at Mad River Bar &amp; Grille (New York, NY) http://t.co/VSiZrzKP\"]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column of processed tweets utilizing the created function above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = [processTweet(i) for i in tweet_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed'].str.contains('timberlake').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_processed'] = df['processed'].map(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>processed</th>\n",
       "      <th>clean_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'262596552399396864'</td>\n",
       "      <td>I've got enough candles to supply a Mexican fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>i've got enough candles to supply a mexican fa...</td>\n",
       "      <td>[i, ve, got, enough, candles, to, supply, a, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'263044104500420609'</td>\n",
       "      <td>Sandy be soooo mad that she be shattering our ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>sandy be soooo mad that she be shattering our ...</td>\n",
       "      <td>[sandy, be, soooo, mad, that, she, be, shatter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'263309629973491712'</td>\n",
       "      <td>@ibexgirl thankfully Hurricane Waugh played it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>ibexgirl thankfully hurricane waugh played it ...</td>\n",
       "      <td>[ibexgirl, thankfully, hurricane, waugh, playe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'263422851133079552'</td>\n",
       "      <td>@taos you never got that magnificent case of B...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>taos you never got that magnificent case of bu...</td>\n",
       "      <td>[taos, you, never, got, that, magnificent, cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'262404311223504896'</td>\n",
       "      <td>I'm at Mad River Bar &amp;amp; Grille (New York, N...</td>\n",
       "      <td>0</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>i'm at mad river bar &amp;amp; grille (new york, n...</td>\n",
       "      <td>[i, m, at, mad, river, bar, amp, grille, new, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet id                                              tweet  \\\n",
       "0  '262596552399396864'  I've got enough candles to supply a Mexican fa...   \n",
       "1  '263044104500420609'  Sandy be soooo mad that she be shattering our ...   \n",
       "2  '263309629973491712'  @ibexgirl thankfully Hurricane Waugh played it...   \n",
       "3  '263422851133079552'  @taos you never got that magnificent case of B...   \n",
       "4  '262404311223504896'  I'm at Mad River Bar &amp; Grille (New York, N...   \n",
       "\n",
       "   label       type                                          processed  \\\n",
       "0      0  hurricane  i've got enough candles to supply a mexican fa...   \n",
       "1      1  hurricane  sandy be soooo mad that she be shattering our ...   \n",
       "2      0  hurricane  ibexgirl thankfully hurricane waugh played it ...   \n",
       "3      0  hurricane  taos you never got that magnificent case of bu...   \n",
       "4      0  hurricane  i'm at mad river bar &amp; grille (new york, n...   \n",
       "\n",
       "                                     clean_processed  \n",
       "0  [i, ve, got, enough, candles, to, supply, a, m...  \n",
       "1  [sandy, be, soooo, mad, that, she, be, shatter...  \n",
       "2  [ibexgirl, thankfully, hurricane, waugh, playe...  \n",
       "3  [taos, you, never, got, that, magnificent, cas...  \n",
       "4  [i, m, at, mad, river, bar, amp, grille, new, ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemm_clean_processed'] = df['clean_processed'].map(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formatted_name, now, file_description = filename_format_log(file_path ='assets/crisislex_df.csv')\n",
    "df.to_csv(formatted_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_clean_processed_list = [i for i in df['lemm_clean_processed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize countvectorizer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_df will remember words that are in a document at least once. For example, if min_df = 3, will only remember words that are a part of 3 documents in a corpus. max_df refers to the %-age of documents within a corpus that a word occurs in. For example, if max_df = 0.9, words that occur in more than 90% of my documents will be ignored. By default, max_df is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,2),\n",
    "                     stop_words = 'english',\n",
    "                     min_df = 15,\n",
    "                     max_df = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.SparseDataFrame(cv.fit_transform(df['lemm_clean_processed']), \n",
    "                     columns = cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getsizeof(df_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform SVD to reduce dimensionality to about ~1000 (Currently ~1800)...Have to run an instance with about ~8GB of RAM (~0.08cents to perform one calculation); shut off the instance and restart this instance.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfidf dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "custom_stop = ['url',\n",
    "               'rt',\n",
    "               'mitchellvii',\n",
    "               'wa',\n",
    "               'ha',\n",
    "               'just',\n",
    "               'good',\n",
    "               'free',\n",
    "               'purchase',\n",
    "               'shipping',\n",
    "               'don',\n",
    "               'buy',\n",
    "               'sale',\n",
    "               'snkrconnecthq',\n",
    "               \n",
    "              ]\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS.union(custom_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2), \n",
    "                        stop_words = 'english', \n",
    "                        min_df = 25, \n",
    "                        max_df = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.SparseDataFrame(tfidf.fit_transform(df['lemm_clean_processed']),\n",
    "                              columns = tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crisislexTFIDF_coo = df_tfidf.to_coo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formatted_name, now, file_description = filename_format_log(file_path ='assets/crisislexTFIDF_coo.npz')\n",
    "sparse.save_npz('assets/crisislexTFIDF_coo.npz', crisislexTFIDF_coo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns = pd.Series(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formatted_name, now, file_description = filename_format_log(file_path ='/assets/TFIDF_col.csv')\n",
    "columns.to_csv('assets/TFIDF_col.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD = TruncatedSVD(n_components=1000) \n",
    "# doesn't center out data...versus PCA which it does...\n",
    "# ##If we didn't fit before train_test_split (WHY DO WE NEED TO FIT TRANSFORM BEFORE TRAIN TEST SPLIT...)\n",
    "svd_matrix = SVD.fit_transform(df_tfidf)\n",
    "svd_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_names = pd.Series([\"component_\"+str(i+1) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.bar(np.array(range(1000))+1, \n",
    "        SVD.explained_variance_ratio_, \n",
    "        color='g', \n",
    "        label='Explained Variance')\n",
    "plt.plot(np.array(range(1000))+1, \n",
    "         np.cumsum(SVD.explained_variance_ratio_), \n",
    "         label='Cumulative Explained Variance')\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel('Component', fontsize=20)\n",
    "plt.ylabel('Variance Ratio', fontsize=20)\n",
    "plt.title('Explained Variance by Component', fontsize=36);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(SVD.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_names = [\"component_\"+str(i+1) for i in range(1000)]\n",
    "svd_df = pd.SparseDataFrame(svd_matrix,columns=component_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = pd.SparseDataFrame(SVD.components_,\n",
    "                              index=component_names,\n",
    "                              columns=df_tfidf.columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings['abs_component_1'] = np.abs(loadings.component_1)\n",
    "loadings['abs_component_2'] = np.abs(loadings.component_2)\n",
    "loadings['abs_component_3'] = np.abs(loadings.component_3)\n",
    "loadings['abs_component_4'] = np.abs(loadings.component_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loadings.sort_values('abs_component_1',ascending=False).head(20)[['component_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings.sort_values('abs_component_2',ascending=False).head(20)[['component_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings.sort_values('abs_component_3',ascending=False).head(20)[['component_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings.sort_values('abs_component_4',ascending=False).head(20)[['component_4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters = 4, n_init = 20, max_iter = 600, random_state=42)\n",
    "km.fit(svd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df['labels_km'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df['type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df['labels_km'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df[crisislex_df['labels_km'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df[['label']][crisislex_df['labels_km'] == 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df[crisislex_df['labels_km'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df[crisislex_df['labels_km'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df[crisislex_df['labels_km'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_mat = pairwise_distances(svd_df, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getsizeof(cos_mat) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = hdbscan.HDBSCAN(min_cluster_size = 150,\n",
    "                          min_samples = 100, \n",
    "                          gen_min_span_tree = True,\n",
    "                          approx_min_span_tree = False,\n",
    "                          prediction_data = True,\n",
    "                          metric = 'precomputed', \n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.fit(cos_mat.astype('float64')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cluster.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df['labels_hdbs'] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df['labels_hdbs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df[crisislex_df['labels_hdbs'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df[crisislex_df['labels_hdbs'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df[crisislex_df['labels_hdbs'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crisislex_df[crisislex_df['labels_hdbs'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "cluster.minimum_spanning_tree_.plot(edge_cmap='viridis',\n",
    "                                    edge_alpha=0.6,\n",
    "                                    node_size=80,\n",
    "                                    edge_linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also visually represent the clustering hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "cluster.single_linkage_tree_.plot(cmap='viridis', colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we condense this plot, we can get a better idea of our final clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "cluster.condensed_tree_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And then we can actually visually represent which clusters are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "cluster.condensed_tree_.plot(select_clusters=True, selection_palette=sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbs_null_index = crisislex_df[crisislex_df['labels_hdbs'] == -1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km2 = KMeans(n_clusters = 2)\n",
    "km2.fit(crisislex_df['lemm_clean_processed'][crisislex_df['labels_hdbs'] == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
