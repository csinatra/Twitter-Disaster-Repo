{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "-  [Configure Postgres Server with Docker](#Configure-Postgres-Server-with-Docker)\n",
    "-  [Application Token](#Application-Token)\n",
    "-  [Collect Tweets](#Collect-Tweets)\n",
    "-  [Retrieve Data from PostgreSQL Database](#Retrieve-Data-from-PostgreSQL-Database)\n",
    "-  [Clean Text](#Clean-Text)\n",
    "-  [Model Prep](#Model-Prep)\n",
    "-  [Logistic Regression Classification](#Logistic-Regression-Classification)\n",
    "-  [Save Data](#Save-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter, json, time, re, nltk\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "from psycopg2.extras import RealDictCursor, Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../sql_test.py\n",
    "%run ../twitter_credentials.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Postgres Server with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to programmatically connect to and insert data into database:\n",
    "-  **con_cur_to_db**: returns both a connection and a cursor object for database\n",
    "-  **execute_query**: executes query directly to database, without having to create a cursor and connection each time\n",
    "-  **insert_entry_json**: inserts data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_db(dbname=DBNAME, dict_cur=None):\n",
    "    con = pg2.connect(host=IP_ADDRESS,\n",
    "                  dbname=dbname,\n",
    "                  user=USER,\n",
    "                  password=PASSWORD)\n",
    "    if dict_cur:\n",
    "        cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    else:\n",
    "        cur = con.cursor()\n",
    "    return con, cur\n",
    "    \n",
    "def execute_query(query, dbname=DBNAME, dict_cur=None, command=False):\n",
    "    con, cur = con_cur_to_db(dbname, dict_cur)\n",
    "    cur.execute(f'{query}')\n",
    "    if not command:\n",
    "        data = cur.fetchall()\n",
    "        con.close()\n",
    "        return data\n",
    "    con.commit() #sends to server\n",
    "    con.close() #closes server connection\n",
    "\n",
    "def insert_entry_json(data, tablename=None):\n",
    "    con, cur = con_cur_to_db()\n",
    "    for x in data:\n",
    "        cur.execute(f'INSERT INTO {tablename} (data) VALUES ({Json(x)});')\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table `raw_tweets` to save our collected data into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query = '''CREATE TABLE raw_tweets\n",
    "(id SERIAL,\n",
    "data JSONB);'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute_query(query, command=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define API keys and instantiate twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = {\n",
    "    'consumer_key':        CONSUMER_KEY,\n",
    "    'consumer_secret':     CONSUMER_SECRET,\n",
    "    'access_token_key':    ACCESS_TOKEN,\n",
    "    'access_token_secret': ACCESS_TOKEN_SECRET\n",
    "}\n",
    "\n",
    "api = twitter.Api(consumer_key         =   twitter_keys['consumer_key'],\n",
    "                  consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "                  access_token_key     =   twitter_keys['access_token_key'],\n",
    "                  access_token_secret  =   twitter_keys['access_token_secret'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect tweets and store into database:\n",
    "-  `term`: term to search by\n",
    "-  `geocode`: specify geolocation within which to search for tweets\n",
    "-  `since`: search for tweets since specified date\n",
    "-  `count`: number of results returned (100 max)\n",
    "-  `sql_db`: database to save tweets to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamTweets(term, geocode, since, count, sql_db):\n",
    "    for i in range(1,8):\n",
    "        year, month, day = since.split('-')\n",
    "        day = int(day)\n",
    "        day-=1\n",
    "        day = str(day).zfill(2)\n",
    "        date = year + month + day\n",
    "        after = datetime.strptime(date, '%Y%m%d').strftime('%Y-%m-%d')\n",
    "        \n",
    "        results = api.GetSearch(\n",
    "            term = term,\n",
    "            geocode = geocode,\n",
    "            return_json = True\n",
    "        )\n",
    "\n",
    "        insert_entry_json(data = results['statuses'], \n",
    "                          tablename = sql_db)\n",
    "        before = after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to have `streamTweets` on a loop to programmatically collect tweets:\n",
    "-  Repeat function 15 times, returning 100 (`count`) each time\n",
    "-  Pause for 40 seconds to avoid exceeding rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_repeater(term, geocode, since, sql_db, repeats=15, count=100):\n",
    "    for i in range(repeats):\n",
    "        since = since\n",
    "        \n",
    "        streamTweets(term, geocode, since, count, sql_db)\n",
    "        print(f'Loop {i+1} complete. Raw tweets pushed to {sql_db}.')\n",
    "        time.sleep(40)\n",
    "        \n",
    "    print('All tweets pulled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect most recent tweets:\n",
    "-  that contains the term `storm` (terms were determined by natural disasters during time of search)\n",
    "-  within 15 mile radius of location\n",
    "-  starting from 2019-01-13\n",
    "-  run function 100 times, collecting 700 tweets (1 week x 100 tweets) each time\n",
    "-  save into `raw_tweets` database\n",
    "-  sample output is displayed \n",
    "\n",
    "We searched over two locations and used the following terms for each:\n",
    "\n",
    "|Location|Latitude|Longitude|Search Terms|Since Date|\n",
    "|---|---|---|---|---|\n",
    "|Malibu, CA|34.0249999|-118.773830238|flood, mudslide, landslide, rain, storm|2019-01-06|\n",
    "|Riverside, CA|33.9806|-117.3755|flood, strom, rain|2019-01-13|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1 complete. Raw tweets pushed to raw_tweets.\n",
      "All tweets pulled.\n"
     ]
    }
   ],
   "source": [
    "tweet_repeater(term='storm',\n",
    "               geocode='33.9806,-117.3755,15mi',\n",
    "               since='2019-01-13',\n",
    "               repeats=100, \n",
    "               count=100,\n",
    "               sql_db='raw_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data from PostgreSQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT * to determine data structure and find information most relevant to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''SELECT * FROM raw_tweets;'''\n",
    "response = execute_query(query, dict_cur=True)\n",
    "print(type(response))\n",
    "print(type(response[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text (Tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is stored as a list of nested dictionaries. We want to retrieve the text itself (`text`), nested under `data` and put it in a dataframe (`df_text`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT data ->> 'text'\n",
    "FROM raw_tweets;\n",
    "\"\"\"\n",
    "response = execute_query(query, dict_cur=True)\n",
    "df_text = pd.DataFrame(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo-Coordinates\n",
    "We then want to retrieve the geo coordinates for each tweet in order to map their location and allocate resources there. This is stored in dataframe `df_geo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?column?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ?column?\n",
       "89   [[[-118.668404, 33.704538], [-118.155409, 33.7...\n",
       "190  [[[-118.668404, 33.704538], [-118.155409, 33.7...\n",
       "191  [[[-118.668404, 33.704538], [-118.155409, 33.7...\n",
       "192  [[[-118.668404, 33.704538], [-118.155409, 33.7...\n",
       "193  [[[-118.668404, 33.704538], [-118.155409, 33.7..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"SELECT data#>'{place,bounding_box,coordinates}'\n",
    "FROM raw_tweets;\n",
    "\"\"\"\n",
    "response = execute_query(query, dict_cur=True)\n",
    "df_geo = pd.DataFrame(response).dropna()\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users that do not have location enabled will return `NaN`, so we'll drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bounding box for the geo-fence is in a nested list. We key into the list and take the average left/right latitude and upper/lower longitude to approximate the location of a given tweet. These values are stored in the `lat` and `long` column, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = []\n",
    "longitude = []\n",
    "\n",
    "for tweet in df_geo['?column?']:\n",
    "    inside = tweet[0][1]\n",
    "    outside = tweet[0][3]\n",
    "    lat = (inside[0] + outside[0])/2\n",
    "    long = (inside[1] + outside[1])/2\n",
    "    latitude.append(lat)\n",
    "    longitude.append(long)\n",
    "    \n",
    "df_geo['lat'] = latitude\n",
    "df_geo['long'] = longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the `lat` and `long` columns were correctly added to df_geo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?column?</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ?column?         lat       long\n",
       "89   [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789\n",
       "190  [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789\n",
       "191  [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789\n",
       "192  [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789\n",
       "193  [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32490, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then drop the nested list stored in `?column?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.drop(columns=['?column?'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge our text and geo-coordinates data into one dataframe, `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_text, df_geo, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every twitter query returns a random subset of tweets containing the specified search term. We drop duplicates to ensure every tweet is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the merged dataframe to ensure the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?column?</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ENCINO UPDATE: LAFD @PIOErikScott says evacuat...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Fire crews keeping an eye on hillside that hav...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>@darreng60 üëçüôè‚ò∫Ô∏è</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ?column?         lat       long\n",
       "89   ENCINO UPDATE: LAFD @PIOErikScott says evacuat... -118.411907  34.020789\n",
       "191  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789\n",
       "193  Fire crews keeping an eye on hillside that hav... -118.411907  34.020789\n",
       "194  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789\n",
       "579                                    @darreng60 üëçüôè‚ò∫Ô∏è -118.411907  34.020789"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming the `?column?` column to prepare for text cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'?column?':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet)\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    tweet = re.sub('@', '', tweet)\n",
    "    tweet = re.sub('rt', '', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = [processTweet(i) for i in df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df['processed'].map(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = df['tokenized'].map(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>processed</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ENCINO UPDATE: LAFD @PIOErikScott says evacuat...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>encino update: lafd pioerikscott says evacuati...</td>\n",
       "      <td>[encino, update, lafd, pioerikscott, says, eva...</td>\n",
       "      <td>encino update lafd pioerikscott say evacuation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>[twdandmetal, axis7173, nearly_depaed, unknown...</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Fire crews keeping an eye on hillside that hav...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>fire crews keeping an eye on hillside that hav...</td>\n",
       "      <td>[fire, crews, keeping, an, eye, on, hillside, ...</td>\n",
       "      <td>fire crew keeping an eye on hillside that have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>[twdandmetal, axis7173, nearly_depaed, unknown...</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>@darreng60 üëçüôè‚ò∫Ô∏è</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>darreng60 üëçüôè‚ò∫Ô∏è</td>\n",
       "      <td>[darreng60]</td>\n",
       "      <td>darreng60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text         lat       long  \\\n",
       "89   ENCINO UPDATE: LAFD @PIOErikScott says evacuat... -118.411907  34.020789   \n",
       "191  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789   \n",
       "193  Fire crews keeping an eye on hillside that hav... -118.411907  34.020789   \n",
       "194  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789   \n",
       "579                                    @darreng60 üëçüôè‚ò∫Ô∏è -118.411907  34.020789   \n",
       "\n",
       "                                             processed  \\\n",
       "89   encino update: lafd pioerikscott says evacuati...   \n",
       "191  twdandmetal axis7173 nearly_depaed unknown_meu...   \n",
       "193  fire crews keeping an eye on hillside that hav...   \n",
       "194  twdandmetal axis7173 nearly_depaed unknown_meu...   \n",
       "579                                     darreng60 üëçüôè‚ò∫Ô∏è   \n",
       "\n",
       "                                             tokenized  \\\n",
       "89   [encino, update, lafd, pioerikscott, says, eva...   \n",
       "191  [twdandmetal, axis7173, nearly_depaed, unknown...   \n",
       "193  [fire, crews, keeping, an, eye, on, hillside, ...   \n",
       "194  [twdandmetal, axis7173, nearly_depaed, unknown...   \n",
       "579                                        [darreng60]   \n",
       "\n",
       "                                            lemmatized  \n",
       "89   encino update lafd pioerikscott say evacuation...  \n",
       "191  twdandmetal axis7173 nearly_depaed unknown_meu...  \n",
       "193  fire crew keeping an eye on hillside that have...  \n",
       "194  twdandmetal axis7173 nearly_depaed unknown_meu...  \n",
       "579                                          darreng60  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with fewer samples than our training dataset we will drop the min_df to 3, ensuring we have a similarly sized vocabulary to run through our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>10yearchallenge</th>\n",
       "      <th>20</th>\n",
       "      <th>2009</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2020 vp</th>\n",
       "      <th>21</th>\n",
       "      <th>24</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wtf</th>\n",
       "      <th>wwe</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>yes</th>\n",
       "      <th>yo</th>\n",
       "      <th>youtube</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 379 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  10yearchallenge   20  2009  2018  2019  2020  2020 vp   21   24  \\\n",
       "0  0.0              0.0  0.0   0.0   0.0   0.0   0.0      0.0  0.0  0.0   \n",
       "1  0.0              0.0  0.0   0.0   0.0   0.0   0.0      0.0  0.0  0.0   \n",
       "2  0.0              0.0  0.0   0.0   0.0   0.0   0.0      0.0  0.0  0.0   \n",
       "3  0.0              0.0  0.0   0.0   0.0   0.0   0.0      0.0  0.0  0.0   \n",
       "4  0.0              0.0  0.0   0.0   0.0   0.0   0.0      0.0  0.0  0.0   \n",
       "\n",
       "    ...     wrong  wtf  wwe   ya  yeah  year  year ago       yes   yo  youtube  \n",
       "0   ...       0.0  0.0  0.0  0.0   0.0   0.0       0.0  0.386262  0.0      0.0  \n",
       "1   ...       0.0  0.0  0.0  0.0   0.0   0.0       0.0  0.000000  0.0      0.0  \n",
       "2   ...       0.0  0.0  0.0  0.0   0.0   0.0       0.0  0.000000  0.0      0.0  \n",
       "3   ...       0.0  0.0  0.0  0.0   0.0   0.0       0.0  0.000000  0.0      0.0  \n",
       "4   ...       0.0  0.0  0.0  0.0   0.0   0.0       0.0  0.000000  0.0      0.0  \n",
       "\n",
       "[5 rows x 379 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 2),\n",
    "                        stop_words='english',\n",
    "                        min_df=3, \n",
    "                        max_df=1.0)\n",
    "tfidf_df = tfidf.fit_transform(df['lemmatized'])\n",
    "tfidf_df = pd.DataFrame(tfidf_df.toarray(), columns=tfidf.get_feature_names())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the trained Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../assets/gs_{now}.pkl', 'rb') as f:\n",
    "    lr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/raw_tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
